<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Radhika Dua</title>

  <meta name="author" content="Radhika Dua">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Radhika Dua</name>
              </p>
              <p>I am a Summer Intern at <a href="https://www.brown.edu/">Brown University</a>, advised by <a href="https://ai.stanford.edu/~ssrinath/">Prof. Srinath Sridhar</a>. Previously, I was a Visiting Researcher at <a href="https://iith.ac.in/">IIT Hyderabad</a>, advised by <a href="https://iith.ac.in/~vineethnb/">Prof. Vineeth N Balasubramanian</a>. I work in Artificial Intelligence at the intersection of Computer Vision, Machine Learning & Natural Language Processing. I am currently exploring the creation of AI that can better understand visual scenes through the use of common sense reasoning.
              <p style="text-align:center">
                <a href="mailto:radhikadua1997@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=SeBAKsUAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Radhikadua123">Github</a>&nbsp/&nbsp
                <a href="https://twitter.com/dua_radhika?lang=en">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="data/rd8.jpeg""><img style="width:100%;max-width:100%" alt="profile photo" src="data/rd4.jpeg"" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>RESEARCH</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, depth, motion, paint, light, colors, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerf_image'>
                  <embed width=100% height=100%  muted autoplay loop src="https://www.youtube.com/embed/tgbNymZ7vqY">
  <!-- <video  width=100% height=100% preload="none" muted autoplay loop>
                  <source type="video/youtube" src="https://www.youtube.com/watch?v=l7-dK4eKxG0#action=share" />
  </video> -->
<!-- </div>
                <img src='data/vase_still.png' width="160">
              </div>
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.matthewtancik.com/nerf">
                <papertitle>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis
</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall*</a>,
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul Srinivasan*</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
        <em>arXiv</em>, 2020
              <br>
              <a href="http://www.matthewtancik.com/nerf">project page</a>
        /
              <a href="https://arxiv.org/abs/2003.08934">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=JuH79E8rdKc">video</a>
        /
              <a href="https://github.com/bmild/nerf">code</a>
              <p></p>
              <p>
              Training a tiny non-convolutional neural network to reproduce a scene using volume rendering achieves photorealistic view synthesis.</p> -->
            <!-- </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle"> -->
              <!-- <a href=""> -->
                <!-- <papertitle> Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions</papertitle> -->
              <!-- </a> -->
              <!-- <br>
              <a href="http://www.eecs.berkeley.edu/%7Eallie/">Allison Janoch</a>,
              <a href="http://sergeykarayev.com/">Sergey Karayev</a>,
              <a href="http://www.eecs.berkeley.edu/%7Ejiayq/">Yangqing Jia</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://www.cs.berkeley.edu/%7Emfritz/">Mario Fritz</a>,
              <a href="http://www.icsi.berkeley.edu/%7Esaenko/">Kate Saenko</a>,
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a>
              <br>
              <em>Under Review</em>,
              <br> -->
              <!-- <a href="data/B3DO_ICCV_2011.bib">bibtex</a> / -->
              <!-- <a href="https://drive.google.com/file/d/1qf4-U5RhSw12O7gzQwW66SMQhs2FWYDW/view?usp=sharing">"smoothing" code</a>
              <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>
            </td>
          </tr>
                  </tbody></table>  -->

                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
                      <tr>
                        <td>
                          <heading>AWARDS AND HONORS</heading>
                        <ul>
                        <li> Serving as a<highlight> volunteer</highlight> for <highlight> ICML 2020 and ACL 2020</highlight></li>
                        <li> Serving as a<highlight> Scholarship Application Reviewer</highlight> for the 2020 Grace Hopper Celebration (GHC 2020)</li>
                        <li> ET Campus Stars by economic times, <highlight>India's brightest engineers</highlight> (2018-2019)</li>
                        <li> <highlight>Grace Hopper Celebration India (GHCI)</highlight> Student Scholarship (2018)</li>
                        <li> <highlight>Second prize in Celestini Project India </highlight> sponsored by Marconi Society and Google (2018)</li>
                        <li> <highlight>Third prize</highlight> in Hack Infinity (2017)</li>
                        <li> <highlight>Second prize</highlight> in Hack In The North (2017)</li>
                        <li> <highlight>Sixth position</highlight> in India Hacks by Hackerearth (2017)</li>
                        </ul>
                      </td></tr>
                    </tbody></table>


                                      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                                          <tr>
                                          <td style="padding:20px;width:100%;vertical-align:middle">
                                            <heading>PUBLICATIONS</heading>
                                          </td>
                                        </tr>
                                      </tbody></table>
                                      <table cellpadding="20" border="0" width="100%" align="center"><tbody>
                                          <tr>
                                        <td style="padding:40px;width:40%;vertical-align:middle"><img src="data/viqar.png" width="100%"></td>
                                        <td width="100%" height="100%"valign="center">
                                            <papertitle>Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions.</papertitle>
                                          <br>
                                          <strong>Radhika Dua</strong>, Sai Srinivas Kancheti, <a href="https://iith.ac.in/~vineethnb/">Prof. Vineeth N Balasubramanian</a>
                                          <br>
                                          <em>Under Review</em>, 2020 (More details coming soon!!)
                                          <br>
                                          <p> We introduce a new task: ViQAR (Visual Question Answering and Reasoning), wherein a model must generate the complete answer and a rationale that seeks to justify the generated answer.
                                          </p>
                                        </td>
                                      </tr>

                                      <tr>
                                    <td style="padding:40px;width:40%;vertical-align:middle"><img src="data/vayu.png" width="100%"></td>
                                    <td width="100%" valign="center">
                                                <papertitle>VayuAnukulani: Adaptive Memory Networks for Air Pollution Forecasting</papertitle>
                                                <br>
                                                <strong>Radhika Dua</strong>, <a href="http://divyam3897.github.io/ ">Divyam Madaan</a>, <a href="http://www.iiits.ac.in/FacPages/index-prerana.html">Dr. Prerana Mukherjee</a>
                                                <br>
                                                <em>GlobalSIP</em>, 2019
                                                <br>
                                                    <a href="https://arxiv.org/pdf/1904.03977.pdf">arxiv</a>
                                                  /
                                              <a href="https://github.com/divyam3897/VayuAnukulani">code</a>
                                               <p>We present VayuAnukulani system, a novel end-to-end solution to forecast fine-grained ambient air quality information based on the historical and realtime ambient air quality and meteorological data.
                                              </p>
                                            </td>
                                          </tr>
                                          </tbody></table>

                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                      <tr>
                      <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>EXPERIENCE</heading>
                      </td>
                    </tr>
                  </tbody></table>
                  <table cellpadding="20" border="0" width="100%" align="center"><tbody>
                    <tr>
                      <td style="padding:40px;width:25%;vertical-align:middle"><img src="data/Brown_University_Logo.png"></td>
                      <td width="80%" valign="center">
                          <papertitle>Summer Intern, Brown University</papertitle>
                        <br><strong>Supervisor:</strong> <a href="http://srinathsridhar.com/">Prof. Srinath Sridhar</a>
                          <p>
                          Conducting research in 3D computer vision and machine learning.
                        </p>
                      </td>
                    </tr>
                      <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle"><img src="data/iith.png"></td>
                        <td width="80%" valign="center">
                            <papertitle>Research Intern, Indian Institute of Technology, Hyderabad</papertitle>
                          <br><strong>Supervisor:</strong> <a href="https://iith.ac.in/~vineethnb/">Prof. Vineeth N Balasubramanian</a>
                            <p>
                              Conducting research in Vision and Language applications and introduced a new task, ViQAR: Visual on
                              Answering and Reasoning, which focuses on automatic generation of the answer, and of a rationale,
                              given a visual query.
                          </p>
                        </td>
                      </tr>
                        <tr>
                        <td style="padding:40px;width:25%;vertical-align:middle"><img src="data/iitd.jpeg"></td>
                        <!-- <td valign="top" width="68%"> -->
                        <td width="80%" valign="center">
                            <papertitle>Research Intern, Celestini Project India</papertitle>
                            <br><strong>Mentor:</strong> <a href="http://www.achowdhery.com/">Dr. Aakanksha Chowdhery</a> (Google Brain and Tensorflow) and <a href="http://web.iitd.ac.in/~brejesh/">Prof. Brejesh Lall</a> (IIT Delhi).
                            <br><strong>Sponsors:</strong>Marconi Society and Google
                            <p>
                              Developed a temporal forecasting solution based on the historical data reported by Central Pollution
                              Control board to predict the real-time and fine-grained air quality information in five locations of Delhi.
                            </p>
                        </td>
                      </tr>
                    </tbody></table>


                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                      <tr>
                      <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>TEACHING</heading>
                      </td>
                    </tr>
                  <table cellpadding="20" border="0" width="100%" align="center">
                    <tbody><tr>
                      <!-- <td style="padding:40px;vertical-align:middle"><img src="data/artificial-intelligence.jpg"></td> -->
                      <td width="40%"><img src="data/artificial-intelligence.jpg"  style="padding:20px;vertical-align:middle;border-radius:15px" width="80%"></td>
                      <td width="80%" valign="center">
                      <a href="https://docs.google.com/document/d/19AyKxnrUFfC3vK0yv8safTyRG2apicTrAp8F1tkMVjg/edit"><papertitle>CS5370: Deep Learning for Computer Vision - Fall 2019 </papertitle></a><br>
                      <br><strong>Instructor</strong>: Prof. Vineeth N Balasubramanian
                      <br>
                      <br>
                          <a href="https://docs.google.com/document/d/17cwez2X6zGBo4K25Iyy1vyqeXU5jtsso0Pu7mvF_HJ4/edit"><papertitle>CS6360: Advanced Topics in
Machine Learning - Spring 2020</papertitle></a><br>
                          <strong>Instructor</strong>: Prof. Vineeth N Balasubramanian
                        <br>
                      </td>
                    </tr>
                  </tbody></table>


                  <!-- <table cellpadding="20" border="0" width="100%" align="center"><tbody>
                      <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle"><img src="data/iith.png"></td>
                        <td width="80%" valign="center"> -->



                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                      <tr>
                      <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>SELECTED PROJECTS</heading>
                      </td>
                    </tr>
                  </tbody></table>
                  <table cellpadding="20" border="0" width="100%" align="center"><tbody>
                      <tr>
                    <td style="padding:40px;width:40%;vertical-align:middle"><img src="data/viqar_proj.png" width="100%"></td>
                    <td width="100%" valign="center">
                        <papertitle>ViQAR: Visual Question Answering and Reasoning</papertitle>
                      <br>
                      <strong>Radhika Dua</strong>, Sai Srinivas Kancheti, <a href="https://iith.ac.in/~vineethnb/">Prof. Vineeth N Balasubramanian</a>
                      <p> We introduced a new task, ViQAR, in which the model generates the complete answer and rationale. We also proposed an end-to-end, attention-based
encoder-decoder architecture to solve this task, and showed that our model generates strong answers and rationales through qualitative and quantitative evaluation, as well as human Turing Test.
                      </p>
                    </td>
                  </tr>

                  <tr>
                    <td style="padding:40px;width:40%;vertical-align:middle">
                          <!-- <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none"> -->
                          <iframe  width=100% height=100% preload="auto" id='nerf_image' muted autoplay loop src="https://www.youtube.com/embed/l7-dK4eKxG0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    </td>
                        <td width="100%" valign="center">
                          <!-- <td width="32%"><img src="data/iitd.jpeg" style="border-radius:15px" width="80%"></td> -->

                            <papertitle>Clair: Air Pollution Prediction </papertitle>
                            <br>
                            <strong>Radhika Dua</strong>, <a href="http://divyam3897.github.io/ ">Divyam Madaan</a>, <a href="http://www.achowdhery.com/">Dr. Aakanksha Chowdhery</a>
                          <p>As a part of the Celestini Project, sponsored by Google and Marconi Society and mentored by Dr. Aakanksha Chowdhery, we developed Clair: Air pollution forecasting in Delhi, a temporal forecasting solution based on the historical data reported by Central Pollution
                          Control board to predict the real-time and fine-grained air quality information in five locations of Delhi. We were awarded Second Prize for our novel solution and also had the opportunity of presenting our work at GlobalSIP 2019.
                                <br>
                                <a href="https://marconiyoungscholars.org/sparking-young-minds-to-solve-air-pollution-and-traffic-fatality-problems/">website</a>
                          /
                                <a href="https://www.youtube.com/watch?v=l7-dK4eKxG0">video</a>
                          /
                                <a href="https://www.financialexpress.com/industry/technology/delhi-pollution-indian-students-build-air-quality-measuring-app-air-congnizer/1373275/">Financial Express</a>
                          /
                                <a href="https://www.hindustantimes.com/education/indian-students-bag-us-award-for-developing-innovative-app-to-check-air-quality-index-levels/story-E6LrYSXEpEcyja7MJRh2TM.html">Hindustan Times</a>
                          /
                                <a href="https://gadgets.ndtv.com/apps/news/delhi-air-pollution-college-students-develop-app-to-measure-air-quality-1943152">NDTV</a>
                          /
                                <a href="https://www.business-standard.com/article/technology/indian-students-win-us-award-for-developing-mobile-app-to-monitor-aqi-level-118110500737_1.html">Business Standard</a>
                          /
                                <a href="https://www.firstpost.com/tech/science/app-to-measures-pollution-levels-created-by-indian-students-wins-global-award-5505721.html">First Post</a>
                          /
                                <a href="https://www.indiatoday.in/education-today/gk-current-affairs/story/air-quality-diwali-delhi-government-measures-1383399-2018-11-06">India Today</a>
                          /
                                <a href="https://www.hindustantimes.com/education/indian-students-bag-us-award-for-developing-innovative-app-to-check-air-quality-index-levels/story-E6LrYSXEpEcyja7MJRh2TM.html">Hindustan Times</a>
                          /
                          <a href="https://github.com/divyam3897/VayuAnukulani">code</a>
                          </p>
                        </td>
                      </tr>
                      </tbody></table>
                        <br>
                        Design and source code from <a href="https://jonbarron.info/">Jon Barron's website</a>.
</html>
