<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Radhika Dua</title>

  <meta name="author" content="Radhika Dua">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Radhika Dua</name>
              </p>
              <p>I am a Visiting Researcher at <a href="https://ai.google/research">IIT Hyderabad</a>, advised by <a href="https://iith.ac.in/~vineethnb/">Prof. Vineeth N Balasubramanian</a>.I work in Artificial Intelligence at the intersection of Computer Vision, Machine Learning & Natural Language Processing. I am currently exploring the creation of AI that can better understand visual scenes through the use of common sense reasoning.
              <p style="text-align:center">
                <a href="mailto:radhikadua1997@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=SeBAKsUAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Radhikadua123">Github</a>&nbsp/&nbsp
                <a href="https://twitter.com/dua_radhika?lang=en">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="data/rd5.jpeg""><img style="width:100%;max-width:100%" alt="profile photo" src="data/rd5.jpeg"" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>RESEARCH</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, depth, motion, paint, light, colors, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerf_image'>
                  <embed width=100% height=100%  muted autoplay loop src="https://www.youtube.com/embed/tgbNymZ7vqY">
  <!-- <video  width=100% height=100% preload="none" muted autoplay loop>
                  <source type="video/youtube" src="https://www.youtube.com/watch?v=l7-dK4eKxG0#action=share" />
  </video> -->
<!-- </div>
                <img src='data/vase_still.png' width="160">
              </div>
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.matthewtancik.com/nerf">
                <papertitle>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis
</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall*</a>,
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul Srinivasan*</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
        <em>arXiv</em>, 2020
              <br>
              <a href="http://www.matthewtancik.com/nerf">project page</a>
        /
              <a href="https://arxiv.org/abs/2003.08934">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=JuH79E8rdKc">video</a>
        /
              <a href="https://github.com/bmild/nerf">code</a>
              <p></p>
              <p>
              Training a tiny non-convolutional neural network to reproduce a scene using volume rendering achieves photorealistic view synthesis.</p> -->
            <!-- </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle"> -->
              <!-- <a href=""> -->
                <!-- <papertitle> Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions</papertitle> -->
              <!-- </a> -->
              <!-- <br>
              <a href="http://www.eecs.berkeley.edu/%7Eallie/">Allison Janoch</a>,
              <a href="http://sergeykarayev.com/">Sergey Karayev</a>,
              <a href="http://www.eecs.berkeley.edu/%7Ejiayq/">Yangqing Jia</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://www.cs.berkeley.edu/%7Emfritz/">Mario Fritz</a>,
              <a href="http://www.icsi.berkeley.edu/%7Esaenko/">Kate Saenko</a>,
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a>
              <br>
              <em>Under Review</em>,
              <br> -->
              <!-- <a href="data/B3DO_ICCV_2011.bib">bibtex</a> / -->
              <!-- <a href="https://drive.google.com/file/d/1qf4-U5RhSw12O7gzQwW66SMQhs2FWYDW/view?usp=sharing">"smoothing" code</a>
              <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>
            </td>
          </tr>
                  </tbody></table>  -->

                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                      <tr>
                      <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>PROJECTS</heading>
                      </td>
                    </tr>
                  </tbody></table>
                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                      <td style="border-radius:15px;width:32%;vertical-align:middle">
                        <img src="data/ViQAR1.png" width=80% style="border-style: none">
                      </td>
                      <td width="75%" valign="middle">
                          <papertitle>ViQAR: Visual Question Answering and Reasoning</papertitle>
                        <p> We introduced a new task, ViQAR, in which the model generates the complete answer and rationale. We also proposed an end-to-end, attention-based
encoder-decoder architecture to solve this task, and showed that our model generates strong answers and rationales through qualitative and quantitative evaluation, as well as human Turing Test.
                              <br>
                        </p>
                      </td>
                    </tr>

                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                      <tr>
                        <td style="border-radius:15px;width:32%;vertical-align:middle">
                          <!-- <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none"> -->
                          <iframe  width=80% height=100% preload="auto" id='nerf_image' muted autoplay loop src="https://www.youtube.com/embed/l7-dK4eKxG0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    </td>
                        <td width="75%" valign="middle">
                          <!-- <td width="32%"><img src="data/iitd.jpeg" style="border-radius:15px" width="80%"></td> -->

                            <papertitle>Clair: Air Pollution Prediction </papertitle>
                          <p>As a part of the Celestini Project, sponsored by Google and Marconi Society and mentored by Dr. Aakanksha Chowdhery, we developed Clair: Air pollution forecasting in Delhi, a temporal forecasting solution based on the historical data reported by Central Pollution
                          Control board to predict the real-time and fine-grained air quality information in five locations of Delhi. We were awarded Second Prize for our novel solution and also had the opportunity of presenting our work at GlobalSIP 2019.
                                <br>
                                <a href="https://marconiyoungscholars.org/sparking-young-minds-to-solve-air-pollution-and-traffic-fatality-problems/">website</a>
                          /
                                <a href="https://www.youtube.com/watch?v=l7-dK4eKxG0">video</a>
                          /
                                <a href="https://www.financialexpress.com/industry/technology/delhi-pollution-indian-students-build-air-quality-measuring-app-air-congnizer/1373275/">Financial Express</a>
                          /
                                <a href="https://www.hindustantimes.com/education/indian-students-bag-us-award-for-developing-innovative-app-to-check-air-quality-index-levels/story-E6LrYSXEpEcyja7MJRh2TM.html">Hindustan Times</a>
                          /
                                <a href="https://gadgets.ndtv.com/apps/news/delhi-air-pollution-college-students-develop-app-to-measure-air-quality-1943152">NDTV</a>
                          /
                                <a href="https://www.business-standard.com/article/technology/indian-students-win-us-award-for-developing-mobile-app-to-monitor-aqi-level-118110500737_1.html">Business Standard</a>
                          /
                                <a href="https://www.firstpost.com/tech/science/app-to-measures-pollution-levels-created-by-indian-students-wins-global-award-5505721.html">First Post</a>
                          /
                                <a href="https://www.indiatoday.in/education-today/gk-current-affairs/story/air-quality-diwali-delhi-government-measures-1383399-2018-11-06">India Today</a>
                          /
                                <a href="https://www.hindustantimes.com/education/indian-students-bag-us-award-for-developing-innovative-app-to-check-air-quality-index-levels/story-E6LrYSXEpEcyja7MJRh2TM.html">Hindustan Times</a>
                          /
                          <a href="https://github.com/divyam3897/VayuAnukulani">code</a>
                          </p>
                        </td>
                      </tr>



                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                      <tr>
                      <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>TEACHING</heading>
                      </td>
                    </tr>
                  <table cellpadding="20" border="0" width="100%" align="center">
                    <tbody><tr>
                      <td width="32%"><img src="data/artificial-intelligence.jpg" alt="pacman" style="border-radius:15px" width="100%"></td>
                      <td valign="top" width="68%">
                        <p>
                          <a href="https://docs.google.com/document/d/19AyKxnrUFfC3vK0yv8safTyRG2apicTrAp8F1tkMVjg/edit"><papertitle>CS5370: Deep Learning for Computer Vision - Fall 2019 </papertitle></a><br>
                          <strong>Instructor</strong>: Prof. Vineeth N Balasubramanian<br>
                        </p>
                        <p>
                          <a href="https://docs.google.com/document/d/17cwez2X6zGBo4K25Iyy1vyqeXU5jtsso0Pu7mvF_HJ4/edit"><papertitle>CS6360: Advanced Topics in
Machine Learning - Spring 2020</papertitle></a><br>
                          <strong>Instructor</strong>: Prof. Vineeth N Balasubramanian<br>
                        </p>
                      </td>
                    </tr>
                  </tbody></table>

                  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
                    <tr>
                      <td>
                        <heading>AWARDS AND HONORS</heading>
                      <ul>
                      <li> Selected to be a Faculty Scholarship Application Reviewer for the 2020 Grace Hopper Celebration (GHC 2020)</li>
                      <li> ET Campus Stars by economic times, India's brightest engineers (2018-2019)</li>
                      <li> Grace Hopper Celebration India (GHCI) Student Scholarship (2018)</li>
                      <li> Second prize in Celestini Project India sponsored by Marconi Society and Google (2018)</li>
                      <li> Third prize in Hack Infinity (2017)</li>
                      <li> Second prize in Hack In The North (2017)</li>
                      <li> Sixth position in India Hacks by Hackerearth (2017)</li>
                      </ul>
                    </td></tr>
                  </tbody></table>
                <br>

                                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                                      <tr>
                                      <td style="padding:20px;width:100%;vertical-align:middle">
                                        <heading>EXPERIENCE</heading>
                                      </td>
                                    </tr>
                                  </tbody></table>
                                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                                    <tr>
                                      <!-- <td style="padding:20px;width:0.5%;vertical-align:middle">
                                        <img src="data/iith.png" width="160" height="120" style="border-style: none">
                                      </td> -->
                                      <td width="32%"><img src="data/iith.png" style="border-radius:15px" width="100%"></td>
                                      <!-- <td valign="top" width="68%"> -->
                                      <td width="75%" valign="middle">
                                          <papertitle>Research Intern, Indian Institute of Technology, Hyderabad</papertitle>
                                        <br><strong>Supervisor:</strong> Prof. Vineeth N Balasubramanian
                                          <p>
                                            Conducting research in Vision and Language applications and introduced a new task, ViQAR: Visual on
                                            Answering and Reasoning, which focuses on automatic generation of the answer, and of a rationale,
                                            given a visual query.
                                        </p>
                                      </td>
                                    </tr>
                                  </table>
                                </body>
                                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                                      <tr>
                                        <!-- <td style="padding:20px;width:0.5%;vertical-align:middle">
                                          <img src="data/iitd.jpeg" width="160" height="120" style="border-style: none">
                                        </td> -->
                                        <td width="32%"><img src="data/iitd.jpeg" style="border-radius:15px" width="80%"></td>
                                        <!-- <td valign="top" width="68%"> -->
                                        <td width="75%" valign="middle">
                                            <papertitle>Research Intern, Celestini Project India</papertitle>
                                            <br><strong>Mentor:</strong> Dr. Aakanksha Chowdhery (Google Brain and Tensorflow) and Prof. Brejesh Lall (IIT Delhi).
                                            <br><strong>Sponsors:</strong>Marconi Society and Google
                                            <p>
                                              Developed a temporal forecasting solution based on the historical data reported by Central Pollution
                                              Control board to predict the real-time and fine-grained air quality information in five locations of Delhi.
                                            </p>
                                        </td>
                                      </tr>
                                  </tbody></table>
                                <br>
                                Design and source code from <a href="https://jonbarron.info/">Jon Barron's website</a>.
</html>
